# ADALINE VS Perceptron
ADALINE and Perceptron networks are simple, single-layer neural networks used for binary classification and regression problems in machine learning. This repository contains codes of the structures of each network, for further understanding the way the two networks work and the way they differ. 

## Structure of ADALINE and Perceptron networks
- Both networks have an input layer and an output layer. 
- The Perceptron has a bias neuron while ADALINE uses an additional weight term to learn the bias. 
- The key difference between ADALINE and perceptron lies in the optimization method used to train the network. While perceptron uses a simple update rule, ADALINE uses the more efficient LMS algorithm. 
- By minimizing the sum of squared errors, ADALINE can find the weights that best fit the training data, leading to faster convergence and more accurate classifications.
- The use of LMS in ADALINE is a significant improvement over the simple perceptron update rule.

## Conclusion
ADALINE and Perceptron networks are simple but powerful neural networks and understanding their structure can help in useing them effectively.



